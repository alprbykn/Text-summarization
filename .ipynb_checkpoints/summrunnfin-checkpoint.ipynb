{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cloudy-department",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-022448662e04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/metin özütleme/hphaos summarunner/modsdsaels/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('C:/Users/user/metin özütleme/hphaos summarunner/models'))\n",
    "#sys.path.append('/path/to/your/model/modules/')\n",
    "#if module_path not in sys.path:\n",
    "sys.path.append(module_path)\n",
    "    \n",
    "#C:/Users/user/metin özütleme/hphaos summarunner/checkpoint/\n",
    "'/C:/Users/user/metin özütleme/hphaos summarunner/checkpoint/'\n",
    "sys.path.append('/metin özütleme/hphaos summarunner/models/')\n",
    "import sys  \n",
    "sys.path.insert(0, '/metin özütleme/hphaos summarunner/modsdsaels/')\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicModule.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class BasicModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        \n",
    "        super(BasicModule,self).__init__()\n",
    "        self.args = args\n",
    "        print(self.args.device)\n",
    "        print()\n",
    "        self.model_name = str(type(self))\n",
    "\n",
    "    def pad_doc(self,words_out,doc_lens):\n",
    "        pad_dim = words_out.size(1)\n",
    "        max_doc_len = max(doc_lens)\n",
    "        sent_input = []\n",
    "        start = 0\n",
    "        for doc_len in doc_lens:\n",
    "            stop = start + doc_len\n",
    "            valid = words_out[start:stop]                                       # (doc_len,2*H)\n",
    "            start = stop\n",
    "            if doc_len == max_doc_len:\n",
    "                sent_input.append(valid.unsqueeze(0))\n",
    "            else:\n",
    "                pad = Variable(torch.zeros(max_doc_len-doc_len,pad_dim))\n",
    "                if self.args.device is not None:\n",
    "                    pad = pad.cuda()\n",
    "                sent_input.append(torch.cat([valid,pad]).unsqueeze(0))          # (1,max_len,2*H)\n",
    "        sent_input = torch.cat(sent_input,dim=0)                                # (B,max_len,2*H)\n",
    "        return sent_input\n",
    "    \n",
    "    def save(self):\n",
    "        checkpoint = {'model':self.state_dict(), 'args': self.args}\n",
    "        best_path = '%s%s_seed_%d.pt' % (self.args.save_dir,self.model_name,self.args.seed)\n",
    "        torch.save(checkpoint,best_path)\n",
    "\n",
    "        return best_path\n",
    "\n",
    "    def load(self, best_path):\n",
    "        if self.args.device is not None:\n",
    "            print(self.args.device)\n",
    "            data = torch.load(best_path)['model']\n",
    "        else:\n",
    "            data = torch.load(best_path, map_location=lambda storage, loc: storage)['model']\n",
    "        self.load_state_dict(data)\n",
    "        if self.args.device is not None:\n",
    "            return self.cuda()\n",
    "        else:\n",
    "            return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BasicModule import BasicModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CNN_RNN(BasicModule):\n",
    "    def __init__(self, args, embed=None):\n",
    "        super(CNN_RNN,self).__init__(args)\n",
    "        self.model_name = 'CNN_RNN'\n",
    "        self.args = args\n",
    "        \n",
    "        Ks = args.kernel_sizes\n",
    "        Ci = args.embed_dim\n",
    "        Co = args.kernel_num\n",
    "        V = args.embed_num\n",
    "        D = args.embed_dim\n",
    "        H = args.hidden_size\n",
    "        S = args.seg_num\n",
    "        P_V = args.pos_num\n",
    "        P_D = args.pos_dim\n",
    "        self.abs_pos_embed = nn.Embedding(P_V,P_D)\n",
    "        self.rel_pos_embed = nn.Embedding(S,P_D)\n",
    "        self.embed = nn.Embedding(V,D,padding_idx=0)\n",
    "        if embed is not None:\n",
    "            self.embed.weight.data.copy_(embed)\n",
    "\n",
    "        self.convs = nn.ModuleList([ nn.Sequential(\n",
    "                                            nn.Conv1d(Ci,Co,K),\n",
    "                                            nn.BatchNorm1d(Co),\n",
    "                                            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "                                            nn.Conv1d(Co,Co,K),\n",
    "                                            nn.BatchNorm1d(Co),\n",
    "                                            nn.LeakyReLU(inplace=True)\n",
    "                                     )\n",
    "                                    for K in Ks])\n",
    "        self.sent_RNN = nn.GRU(\n",
    "                        input_size = Co * len(Ks),\n",
    "                        hidden_size = H,\n",
    "                        batch_first = True,\n",
    "                        bidirectional = True\n",
    "                        )\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(2*H,2*H),\n",
    "                nn.BatchNorm1d(2*H),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "        # Parameters of Classification Layer\n",
    "        self.content = nn.Linear(2*H,1,bias=False)\n",
    "        self.salience = nn.Bilinear(2*H,2*H,1,bias=False)\n",
    "        self.novelty = nn.Bilinear(2*H,2*H,1,bias=False)\n",
    "        self.abs_pos = nn.Linear(P_D,1,bias=False)\n",
    "        self.rel_pos = nn.Linear(P_D,1,bias=False)\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1,0.1))\n",
    "\n",
    "    def max_pool1d(self,x,seq_lens):\n",
    "        # x:[N,L,O_in]\n",
    "        out = []\n",
    "        for index,t in enumerate(x):\n",
    "            t = t[:seq_lens[index],:]\n",
    "            t = torch.t(t).unsqueeze(0)\n",
    "            out.append(F.max_pool1d(t,t.size(2)))\n",
    "        \n",
    "        out = torch.cat(out).squeeze(2)\n",
    "        return out\n",
    "    def avg_pool1d(self,x,seq_lens):\n",
    "        # x:[N,L,O_in]\n",
    "        out = []\n",
    "        for index,t in enumerate(x):\n",
    "            t = t[:seq_lens[index],:]\n",
    "            t = torch.t(t).unsqueeze(0)\n",
    "            out.append(F.avg_pool1d(t,t.size(2)))\n",
    "        \n",
    "        out = torch.cat(out).squeeze(2)\n",
    "        return out\n",
    "    def forward(self,x,doc_lens):\n",
    "        sent_lens = torch.sum(torch.sign(x),dim=1).data \n",
    "        H = self.args.hidden_size\n",
    "        x = self.embed(x)                                                       # (N,L,D)\n",
    "        # word level GRU\n",
    "        x = [conv(x.permute(0,2,1)) for conv in self.convs]\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
    "        x = torch.cat(x,1)\n",
    "        # make sent features(pad with zeros)\n",
    "        x = self.pad_doc(x,doc_lens)\n",
    "\n",
    "        # sent level GRU\n",
    "        sent_out = self.sent_RNN(x)[0]                                           # (B,max_doc_len,2*H)\n",
    "        docs = self.max_pool1d(sent_out,doc_lens)                                # (B,2*H)\n",
    "        docs = self.fc(docs)\n",
    "        probs = []\n",
    "        for index,doc_len in enumerate(doc_lens):\n",
    "            valid_hidden = sent_out[index,:doc_len,:]                            # (doc_len,2*H)\n",
    "            doc = docs[index].unsqueeze(0)\n",
    "            s = Variable(torch.zeros(1,2*H))\n",
    "            if self.args.device is not None:\n",
    "                s = s.cuda()\n",
    "            for position, h in enumerate(valid_hidden):\n",
    "                h = h.view(1, -1)                                                # (1,2*H)\n",
    "                # get position embeddings\n",
    "                abs_index = Variable(torch.LongTensor([[position]]))\n",
    "                if self.args.device is not None:\n",
    "                    abs_index = abs_index.cuda()\n",
    "                abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n",
    "                \n",
    "                rel_index = int(round((position + 1) * 9.0 / doc_len))\n",
    "                rel_index = Variable(torch.LongTensor([[rel_index]]))\n",
    "                if self.args.device is not None:\n",
    "                    rel_index = rel_index.cuda()\n",
    "                rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n",
    "                \n",
    "                # classification layer\n",
    "                content = self.content(h) \n",
    "                salience = self.salience(h,doc)\n",
    "                novelty = -1 * self.novelty(h,F.tanh(s))\n",
    "                abs_p = self.abs_pos(abs_features)\n",
    "                rel_p = self.rel_pos(rel_features)\n",
    "                prob = F.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n",
    "                s = s + torch.mm(prob,h)\n",
    "                probs.append(prob)\n",
    "        return torch.cat(probs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    r\"\"\"\n",
    "    Applies an attention mechanism on the query features from the decoder.\n",
    "    .. math::\n",
    "            \\begin{array}{ll}\n",
    "            x = context*query \\\\\n",
    "            attn_scores = exp(x_i) / sum_j exp(x_j) \\\\\n",
    "            attn_out = attn * context\n",
    "            \\end{array}\n",
    "    Args:\n",
    "        dim(int): The number of expected features in the query\n",
    "    Inputs: query, context\n",
    "        - **query** (batch, query_len, dimensions): tensor containing the query features from the decoder.\n",
    "        - **context** (batch, input_len, dimensions): tensor containing features of the encoded input sequence.\n",
    "    Outputs: query, attn\n",
    "        - **query** (batch, query_len, dimensions): tensor containing the attended query features from the decoder.\n",
    "        - **attn** (batch, query_len, input_len): tensor containing attention weights.\n",
    "    Attributes:\n",
    "        mask (torch.Tensor, optional): applies a :math:`-inf` to the indices specified in the `Tensor`.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.mask = None\n",
    "\n",
    "    def set_mask(self, mask):\n",
    "        \"\"\"\n",
    "        Sets indices to be masked\n",
    "        Args:\n",
    "            mask (torch.Tensor): tensor containing indices to be masked\n",
    "        \"\"\"\n",
    "        self.mask = mask\n",
    "    \n",
    "    \"\"\"\n",
    "        - query   (batch, query_len, dimensions): tensor containing the query features from the decoder.\n",
    "        - context (batch, input_len, dimensions): tensor containing features of the encoded input sequence.\n",
    "    \"\"\"\n",
    "    def forward(self, query, context):\n",
    "        batch_size = query.size(0)\n",
    "        dim = query.size(2)\n",
    "        in_len = context.size(1)\n",
    "        # (batch, query_len, dim) * (batch, in_len, dim) -> (batch, query_len, in_len)\n",
    "        attn = torch.bmm(query, context.transpose(1, 2))\n",
    "        if self.mask is not None:\n",
    "            attn.data.masked_fill_(self.mask, -float('inf'))\n",
    "        attn_scores = F.softmax(attn.view(-1, in_len),dim=1).view(batch_size, -1, in_len)\n",
    "\n",
    "        # (batch, query_len, in_len) * (batch, in_len, dim) -> (batch, query_len, dim)\n",
    "        attn_out = torch.bmm(attn_scores, context)\n",
    "\n",
    "        return attn_out, attn_scores\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(1)\n",
    "    attention = Attention()\n",
    "    context = Variable(torch.randn(10, 20, 4))\n",
    "    query = Variable(torch.randn(10, 1, 4))\n",
    "    query, attn = attention(query, context)\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#coding:utf8\n",
    "from BasicModule import BasicModule\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from .Attention import Attention\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class AttnRNN(BasicModule):\n",
    "    def __init__(self, args, embed=None):\n",
    "        super(AttnRNN,self).__init__(args)\n",
    "        self.model_name = 'AttnRNN'\n",
    "        self.args = args\n",
    "        \n",
    "        V = args.embed_num\n",
    "        D = args.embed_dim\n",
    "        H = args.hidden_size\n",
    "        S = args.seg_num\n",
    "\n",
    "        P_V = args.pos_num\n",
    "        P_D = args.pos_dim\n",
    "        self.abs_pos_embed = nn.Embedding(P_V,P_D)\n",
    "        self.rel_pos_embed = nn.Embedding(S,P_D)\n",
    "        self.embed = nn.Embedding(V,D,padding_idx=0)\n",
    "        if embed is not None:\n",
    "            self.embed.weight.data.copy_(embed)\n",
    "\n",
    "        self.attn = Attention()\n",
    "        self.word_query = nn.Parameter(torch.randn(1,1,2*H))\n",
    "        self.sent_query = nn.Parameter(torch.randn(1,1,2*H))\n",
    "\n",
    "        self.word_RNN = nn.GRU(\n",
    "                        input_size = D,\n",
    "                        hidden_size = H,\n",
    "                        batch_first = True,\n",
    "                        bidirectional = True\n",
    "                        )\n",
    "        self.sent_RNN = nn.GRU(\n",
    "                        input_size = 2*H,\n",
    "                        hidden_size = H,\n",
    "                        batch_first = True,\n",
    "                        bidirectional = True\n",
    "                        )\n",
    "               \n",
    "        self.fc = nn.Linear(2*H,2*H)\n",
    "\n",
    "        # Parameters of Classification Layer\n",
    "        self.content = nn.Linear(2*H,1,bias=False)\n",
    "        self.salience = nn.Bilinear(2*H,2*H,1,bias=False)\n",
    "        self.novelty = nn.Bilinear(2*H,2*H,1,bias=False)\n",
    "        self.abs_pos = nn.Linear(P_D,1,bias=False)\n",
    "        self.rel_pos = nn.Linear(P_D,1,bias=False)\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1,0.1))\n",
    "    def forward(self,x,doc_lens):\n",
    "        N = x.size(0)\n",
    "        L = x.size(1)\n",
    "        B = len(doc_lens)\n",
    "        H = self.args.hidden_size\n",
    "        word_mask = torch.ones_like(x) - torch.sign(x)\n",
    "        word_mask = word_mask.data.type(torch.cuda.ByteTensor).view(N,1,L)\n",
    "        \n",
    "        x = self.embed(x)                                # (N,L,D)\n",
    "        x,_ = self.word_RNN(x)\n",
    "        \n",
    "        # attention\n",
    "        query = self.word_query.expand(N,-1,-1).contiguous()\n",
    "        self.attn.set_mask(word_mask)\n",
    "        word_out = self.attn(query,x)[0].squeeze(1)      # (N,2*H)\n",
    "\n",
    "        x = self.pad_doc(word_out,doc_lens)\n",
    "        # sent level GRU\n",
    "        sent_out = self.sent_RNN(x)[0]                                           # (B,max_doc_len,2*H)\n",
    "        #docs = self.avg_pool1d(sent_out,doc_lens)                               # (B,2*H)\n",
    "        max_doc_len = max(doc_lens)\n",
    "        mask = torch.ones(B,max_doc_len)\n",
    "        for i in range(B):\n",
    "            for j in range(doc_lens[i]):\n",
    "                mask[i][j] = 0\n",
    "        sent_mask = mask.type(torch.cuda.ByteTensor).view(B,1,max_doc_len)\n",
    "        \n",
    "        # attention\n",
    "        query = self.sent_query.expand(B,-1,-1).contiguous()\n",
    "        self.attn.set_mask(sent_mask)\n",
    "        docs = self.attn(query,x)[0].squeeze(1)      # (B,2*H)\n",
    "        probs = []\n",
    "        for index,doc_len in enumerate(doc_lens):\n",
    "            valid_hidden = sent_out[index,:doc_len,:]                            # (doc_len,2*H)\n",
    "            doc = F.tanh(self.fc(docs[index])).unsqueeze(0)\n",
    "            s = Variable(torch.zeros(1,2*H))\n",
    "            if self.args.device is not None:\n",
    "                s = s.cuda()\n",
    "            for position, h in enumerate(valid_hidden):\n",
    "                h = h.view(1, -1)                                                # (1,2*H)\n",
    "                # get position embeddings\n",
    "                abs_index = Variable(torch.LongTensor([[position]]))\n",
    "                if self.args.device is not None:\n",
    "                    abs_index = abs_index.cuda()\n",
    "                abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n",
    "                \n",
    "                rel_index = int(round((position + 1) * 9.0 / doc_len))\n",
    "                rel_index = Variable(torch.LongTensor([[rel_index]]))\n",
    "                if self.args.device is not None:\n",
    "                    rel_index = rel_index.cuda()\n",
    "                rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n",
    "                \n",
    "                # classification layer\n",
    "                content = self.content(h) \n",
    "                salience = self.salience(h,doc)\n",
    "                novelty = -1 * self.novelty(h,F.tanh(s))\n",
    "                abs_p = self.abs_pos(abs_features)\n",
    "                rel_p = self.rel_pos(rel_features)\n",
    "                prob = F.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n",
    "                s = s + torch.mm(prob,h)\n",
    "                #print position,F.sigmoid(abs_p + rel_p)\n",
    "                probs.append(prob)\n",
    "        return torch.cat(probs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.ipynb import BasicModule\n",
    "#from .RNN_RNN import RNN_RNN\n",
    "#from .CNN_RNN import CNN_RNN\n",
    "#from .AttnRNN import \n",
    "import sys  \n",
    "sys.path.insert(0, '/path/to/application/app/folder')\n",
    "\n",
    "import file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Vocab():\n",
    "    def __init__(self,embed,word2id):\n",
    "        self.embed = embed\n",
    "        self.word2id = word2id\n",
    "        self.id2word = {v:k for k,v in word2id.items()}\n",
    "        assert len(self.word2id) == len(self.id2word)\n",
    "        self.PAD_IDX = 0\n",
    "        self.UNK_IDX = 1\n",
    "        self.PAD_TOKEN = 'PAD_TOKEN'\n",
    "        self.UNK_TOKEN = 'UNK_TOKEN'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(word2id)\n",
    "\n",
    "    def i2w(self,idx):\n",
    "        return self.id2word[idx]\n",
    "    def w2i(self,w):\n",
    "        if w in self.word2id:\n",
    "            return self.word2id[w]\n",
    "        else:\n",
    "            return self.UNK_IDX\n",
    "    \n",
    "    def make_features(self,batch,sent_trunc=50,doc_trunc=100,split_token='\\n'):\n",
    "        sents_list,targets,doc_lens = [],[],[]\n",
    "        # trunc document\n",
    "        for doc,label in zip(batch['doc'],batch['labels']):\n",
    "            sents = doc.split(split_token)\n",
    "            labels = label.split(split_token)\n",
    "            labels = [int(l) for l in labels]\n",
    "            max_sent_num = min(doc_trunc,len(sents))\n",
    "            sents = sents[:max_sent_num]\n",
    "            labels = labels[:max_sent_num]\n",
    "            sents_list += sents\n",
    "            targets += labels\n",
    "            doc_lens.append(len(sents))\n",
    "        # trunc or pad sent\n",
    "        max_sent_len = 0\n",
    "        batch_sents = []\n",
    "        for sent in sents_list:\n",
    "            words = sent.split()\n",
    "            if len(words) > sent_trunc:\n",
    "                words = words[:sent_trunc]\n",
    "            max_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
    "            batch_sents.append(words)\n",
    "        \n",
    "        features = []\n",
    "        for sent in batch_sents:\n",
    "            feature = [self.w2i(w) for w in sent] + [self.PAD_IDX for _ in range(max_sent_len-len(sent))]\n",
    "            features.append(feature)\n",
    "        \n",
    "        features = torch.LongTensor(features)    \n",
    "        targets = torch.LongTensor(targets)\n",
    "        summaries = batch['summaries']\n",
    "\n",
    "        return features,targets,summaries,doc_lens\n",
    "\n",
    "    def make_predict_features(self, batch, sent_trunc=150, doc_trunc=100, split_token='. '):\n",
    "        sents_list, doc_lens = [],[]\n",
    "        for doc in batch:\n",
    "            sents = doc.split(split_token)\n",
    "            max_sent_num = min(doc_trunc,len(sents))\n",
    "            sents = sents[:max_sent_num]\n",
    "            sents_list += sents\n",
    "            doc_lens.append(len(sents))\n",
    "        # trunc or pad sent\n",
    "        max_sent_len = 0\n",
    "        batch_sents = []\n",
    "        for sent in sents_list:\n",
    "            words = sent.split()\n",
    "            if len(words) > sent_trunc:\n",
    "                words = words[:sent_trunc]\n",
    "            max_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
    "            batch_sents.append(words)\n",
    "\n",
    "        features = []\n",
    "        for sent in batch_sents:\n",
    "            feature = [self.w2i(w) for w in sent] + [self.PAD_IDX for _ in range(max_sent_len-len(sent))]\n",
    "            features.append(feature)\n",
    "\n",
    "        features = torch.LongTensor(features)\n",
    "\n",
    "        return features, doc_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "#from Vocab import Vocab\n",
    "import numpy as np\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, examples):\n",
    "        super(Dataset,self).__init__()\n",
    "        # data: {'sents':xxxx,'labels':'xxxx', 'summaries':[1,0]}\n",
    "        self.examples = examples \n",
    "        self.training = True\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "        return self\n",
    "    def test(self):\n",
    "        self.training = True\n",
    "        return self\n",
    "    def shuffle(self,words):\n",
    "        np.random.shuffle(words)\n",
    "        return ' '.join(words)\n",
    "    def dropout(self,words,p=0.3):\n",
    "        l = len(words)\n",
    "        drop_index = np.random.choice(l,int(l*p))\n",
    "        keep_words = [words[i] for i in range(l) if i not in drop_index]\n",
    "        return ' '.join(keep_words)\n",
    "    def __getitem__(self, idx):\n",
    "        ex = self.examples[idx]\n",
    "        return ex\n",
    "        #words = ex['sents'].split()\n",
    "        #guess = np.random.random()\n",
    "\n",
    "        #if self.training:\n",
    "        #    if guess > 0.5:\n",
    "        #        sents = self.dropout(words,p=0.3)\n",
    "        #    else:\n",
    "        #        sents = self.shuffle(words)\n",
    "        #else:\n",
    "        #    sents = ex['sents']\n",
    "        #return {'id':ex['id'],'sents':sents,'labels':ex['labels']}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BasicModule import BasicModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN_RNN(BasicModule):\n",
    "    def __init__(self, args, embed=None):\n",
    "        super(RNN_RNN, self).__init__(args)\n",
    "        self.model_name = 'RNN_RNN'\n",
    "        self.args = args\n",
    "        \n",
    "        V = args.embed_num\n",
    "        D = args.embed_dim\n",
    "        H = args.hidden_size\n",
    "        S = args.seg_num\n",
    "        P_V = args.pos_num\n",
    "        P_D = args.pos_dim\n",
    "        self.abs_pos_embed = nn.Embedding(P_V,P_D)\n",
    "        self.rel_pos_embed = nn.Embedding(S,P_D)\n",
    "        self.embed = nn.Embedding(V,D,padding_idx=0)\n",
    "        if embed is not None:\n",
    "            self.embed.weight.data.copy_(embed)\n",
    "\n",
    "        self.word_RNN = nn.GRU(\n",
    "                        input_size = D,\n",
    "                        hidden_size = H,\n",
    "                        batch_first = True,\n",
    "                        bidirectional = True\n",
    "                        )\n",
    "        self.sent_RNN = nn.GRU(\n",
    "                        input_size = 2*H,\n",
    "                        hidden_size = H,\n",
    "                        batch_first = True,\n",
    "                        bidirectional = True\n",
    "                        )\n",
    "        self.fc = nn.Linear(2*H,2*H)\n",
    "\n",
    "        # Parameters of Classification Layer\n",
    "        self.content = nn.Linear(2*H,1,bias=False)\n",
    "        self.salience = nn.Bilinear(2*H,2*H,1,bias=False)\n",
    "        self.novelty = nn.Bilinear(2*H,2*H,1,bias=False)\n",
    "        self.abs_pos = nn.Linear(P_D,1,bias=False)\n",
    "        self.rel_pos = nn.Linear(P_D,1,bias=False)\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1,0.1))\n",
    "\n",
    "    def max_pool1d(self,x,seq_lens):\n",
    "        # x:[N,L,O_in]\n",
    "        out = []\n",
    "        for index,t in enumerate(x):\n",
    "            t = t[:seq_lens[index],:]\n",
    "            t = torch.t(t).unsqueeze(0)\n",
    "            out.append(F.max_pool1d(t,t.size(2)))\n",
    "        \n",
    "        out = torch.cat(out).squeeze(2)\n",
    "        return out\n",
    "    def avg_pool1d(self,x,seq_lens):\n",
    "        # x:[N,L,O_in]\n",
    "        out = []\n",
    "        for index,t in enumerate(x):\n",
    "            t = t[:seq_lens[index],:]\n",
    "            t = torch.t(t).unsqueeze(0)\n",
    "            out.append(F.avg_pool1d(t,t.size(2)))\n",
    "        \n",
    "        out = torch.cat(out).squeeze(2)\n",
    "        return out\n",
    "    def forward(self,x,doc_lens):\n",
    "        sent_lens = torch.sum(torch.sign(x),dim=1).data \n",
    "        x = self.embed(x)                                                      # (N,L,D)\n",
    "        # word level GRU\n",
    "        H = self.args.hidden_size\n",
    "        x = self.word_RNN(x)[0]                                                 # (N,2*H,L)\n",
    "        #word_out = self.avg_pool1d(x,sent_lens)\n",
    "        word_out = self.max_pool1d(x,sent_lens)\n",
    "        # make sent features(pad with zeros)\n",
    "        x = self.pad_doc(word_out,doc_lens)\n",
    "\n",
    "        # sent level GRU\n",
    "        sent_out = self.sent_RNN(x)[0]                                           # (B,max_doc_len,2*H)\n",
    "        #docs = self.avg_pool1d(sent_out,doc_lens)                               # (B,2*H)\n",
    "        docs = self.max_pool1d(sent_out,doc_lens)                                # (B,2*H)\n",
    "        probs = []\n",
    "        for index,doc_len in enumerate(doc_lens):\n",
    "            valid_hidden = sent_out[index,:doc_len,:]                            # (doc_len,2*H)\n",
    "            doc = F.tanh(self.fc(docs[index])).unsqueeze(0)\n",
    "            s = Variable(torch.zeros(1,2*H))\n",
    "            if self.args.device is not None:\n",
    "                s = s.cuda()\n",
    "            for position, h in enumerate(valid_hidden):\n",
    "                h = h.view(1, -1)                                                # (1,2*H)\n",
    "                # get position embeddings\n",
    "                abs_index = Variable(torch.LongTensor([[position]]))\n",
    "                if self.args.device is not None:\n",
    "                    abs_index = abs_index.cuda()\n",
    "                abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n",
    "                \n",
    "                rel_index = int(round((position + 1) * 9.0 / doc_len))\n",
    "                rel_index = Variable(torch.LongTensor([[rel_index]]))\n",
    "                if self.args.device is not None:\n",
    "                    rel_index = rel_index.cuda()\n",
    "                rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n",
    "                \n",
    "                # classification layer\n",
    "                content = self.content(h) \n",
    "                salience = self.salience(h,doc)\n",
    "                novelty = -1 * self.novelty(h,F.tanh(s))\n",
    "                abs_p = self.abs_pos(abs_features)\n",
    "                rel_p = self.rel_pos(rel_features)\n",
    "                prob = F.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n",
    "                s = s + torch.mm(prob,h)\n",
    "                probs.append(prob)\n",
    "        return torch.cat(probs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import models\n",
    "#import utils\n",
    "import argparse,random,logging,numpy,os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "print(models)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [INFO] %(message)s')\n",
    "parser = argparse.ArgumentParser(description='extractive summary')\n",
    "# model\n",
    "\n",
    "parser.add_argument('-save_dir',type=str,default='C:/Users/user/Desktop/sondönem/bitirme/checkpoints/')\n",
    "parser.add_argument('-embed_dim',type=int,default=100)\n",
    "parser.add_argument('-embed_num',type=int,default=100)\n",
    "parser.add_argument('-pos_dim',type=int,default=50)\n",
    "parser.add_argument('-pos_num',type=int,default=100)\n",
    "parser.add_argument('-seg_num',type=int,default=10)\n",
    "parser.add_argument('-kernel_num',type=int,default=100)\n",
    "parser.add_argument('-kernel_sizes',type=str,default='3,4,5')\n",
    "parser.add_argument('-model',type=str,default='RNN_RNN')\n",
    "parser.add_argument('-hidden_size',type=int,default=200)\n",
    "# train\n",
    "parser.add_argument('-lr',type=float,default=1e-3)\n",
    "parser.add_argument('-batch_size',type=int,default=16)\n",
    "parser.add_argument('-epochs',type=int,default=1)\n",
    "parser.add_argument('-seed',type=int,default=1)\n",
    "parser.add_argument('-train_dir',type=str,default='C:/Users/user/metin özütleme/hphaos summarunner/data/train.json')\n",
    "parser.add_argument('-val_dir',type=str,default='C:/Users/user/metin özütleme/hphaos summarunner/data/val.json')\n",
    "parser.add_argument('-embedding',type=str,default='C:/Users/user/metin özütleme/hphaos summarunner/data/embedding.npz')\n",
    "parser.add_argument('-word2id',type=str,default='C:/Users/user/metin özütleme/hphaos summarunner/data/word2id.json')\n",
    "parser.add_argument('-report_every',type=int,default=1500)\n",
    "parser.add_argument('-seq_trunc',type=int,default=50)\n",
    "parser.add_argument('-max_norm',type=float,default=1.0)\n",
    "# test\n",
    "parser.add_argument('-load_dir',type=str,default='C:/Users/user/Desktop/sondönem/bitirme/checkpoints/RNN_RNN_seed_1.pt')\n",
    "parser.add_argument('-test_dir',type=str,default='C:/Users/user/metin özütleme/hphaos summarunner/data/test.json')\n",
    "parser.add_argument('-ref',type=str,default='C:/Users/user/Desktop/sondönem/bitirme/outputs/ref')\n",
    "parser.add_argument('-hyp',type=str,default='C:/Users/user/Desktop/sondönem/bitirme/outputs/hyp')\n",
    "parser.add_argument('-filename',type=str,default='x.txt') # TextFile to be summarized\n",
    "parser.add_argument('-topk',type=int,default=15)\n",
    "# device\n",
    "parser.add_argument('-device',type=int,default=0)\n",
    "# option\n",
    "parser.add_argument('-test',action='store_true')\n",
    "parser.add_argument('-debug',action='store_true')\n",
    "parser.add_argument('-predict',action='store_true')\n",
    "args = parser.parse_args()\n",
    "print(args.device)\n",
    "use_gpu = args.device is not None\n",
    "#use_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available() and not use_gpu:\n",
    "    print(\"WARNING: You have a CUDA device, should run with -device 0\")\n",
    "    if torch.cuda.is_available():  \n",
    "        dev = \"cuda:0\" \n",
    "        use_gpu=dev\n",
    "        torch.cuda.set_device(0)\n",
    "    else:  \n",
    "        dev = \"cpu\"  \n",
    "        device = torch.device(dev)  \n",
    "        \n",
    "print(use_gpu)\n",
    "print(torch.cuda.current_device(),\"device 0\",torch.cuda.device(0),\"count\",torch.cuda.device_count(),\"name\", torch.cuda.get_device_name(0) )\n",
    "\n",
    "# set cuda device and seed\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.device)\n",
    "    print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "numpy.random.seed(args.seed) \n",
    "def eval(net,vocab,data_iter,criterion):\n",
    "    net.eval()\n",
    "    total_loss = 0\n",
    "    batch_num = 0\n",
    "    for batch in data_iter:\n",
    "        features,targets,_,doc_lens = vocab.make_features(batch)\n",
    "        features,targets = Variable(features), Variable(targets.float())\n",
    "        if use_gpu:\n",
    "\n",
    "            features = features.cuda()\n",
    "            targets = targets.cuda()\n",
    "        probs = net(features,doc_lens)\n",
    "        loss = criterion(probs,targets)\n",
    "        total_loss += loss.data\n",
    "        batch_num += 1\n",
    "    loss = total_loss / batch_num\n",
    "    net.train()\n",
    "    print(\"done eval\")\n",
    "    return loss\n",
    "\n",
    "def train():\n",
    "    logging.info('Loading vocab,train and val dataset.Wait a second,please')\n",
    "    \n",
    "    embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
    "    with open(args.word2id,encoding = 'utf8') as f:\n",
    "        word2id = json.load(f)\n",
    "    vocab = Vocab(embed, word2id)\n",
    "\n",
    "    with open(args.train_dir,encoding=\"utf8\") as f:\n",
    "        examples = [json.loads(line) for line in f]\n",
    "    train_dataset = Dataset(examples)\n",
    "    with open(args.val_dir,encoding=\"utf8\") as f:\n",
    "        examples = [json.loads(line) for line in f]\n",
    "    val_dataset = Dataset(examples)\n",
    "    # update args\n",
    "    args.embed_num = embed.size(0)\n",
    "    args.embed_dim = embed.size(1)\n",
    "    args.kernel_sizes = [int(ks) for ks in args.kernel_sizes.split(',')]\n",
    "    # build model\n",
    "    net = getattr(models,args.model)(args,embed)######################33232132131232131232130123912931203912093129301293012930129302193012930219\n",
    "    if use_gpu:\n",
    "        net.cuda()\n",
    "    # load dataset\n",
    "    train_iter = DataLoader(dataset=train_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True)\n",
    "    val_iter = DataLoader(dataset=val_dataset,\n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=False)\n",
    "    # loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    # model info\n",
    "    print(net)\n",
    "    params = sum(p.numel() for p in list(net.parameters())) / 1e6\n",
    "    print('#Params: %.1fM' % (params))\n",
    "    \n",
    "    min_loss = float('inf')\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=args.lr)\n",
    "    net.train()\n",
    "    t1 = time() \n",
    "    for epoch in range(1,args.epochs+1):\n",
    "        for i,batch in enumerate(train_iter):\n",
    "            features,targets,_,doc_lens = vocab.make_features(batch)\n",
    "            features,targets = Variable(features), Variable(targets.float())\n",
    "            if use_gpu:\n",
    "                features = features.cuda()\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            probs = net(features,doc_lens)\n",
    "            loss = criterion(probs,targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm(net.parameters(), args.max_norm)\n",
    "            optimizer.step()\n",
    "           \n",
    "            if args.debug:\n",
    "                print('Batch ID:%d Loss:%f' %(i,loss.data[0]))\n",
    "                continue\n",
    "            if i % args.report_every == 0:\n",
    "                cur_loss = eval(net,vocab,val_iter,criterion)\n",
    "                if cur_loss < min_loss:\n",
    "                    min_loss = cur_loss\n",
    "                    best_path = net.save()\n",
    "                logging.info('Epoch: %2d Min_Val_Loss: %f Cur_Val_Loss: %f'\n",
    "                        % (epoch,min_loss,cur_loss))\n",
    "            \n",
    "    t2 = time()\n",
    "    print(\"train ended\")\n",
    "    logging.info('Total Cost:%f h'%((t2-t1)/3600))\n",
    "\n",
    "def test():\n",
    "    print(\"test started\")\n",
    "    embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
    "    with open(args.word2id,encoding=\"utf8\") as f:\n",
    "        word2id = json.load(f)\n",
    "    vocab = Vocab(embed, word2id)\n",
    "\n",
    "    with open(args.test_dir,encoding=\"utf8\") as f:\n",
    "        examples = [json.loads(line) for line in f]\n",
    "    test_dataset = Dataset(examples)\n",
    "\n",
    "    test_iter = DataLoader(dataset=test_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False)\n",
    "    \n",
    "    if use_gpu:\n",
    "        checkpoint = torch.load(args.load_dir)#-load_dir',type=str,default='C:/Users/user/metin özütleme/hphaos summarunner/checkpoint/RNN_RNN_seed_1.pt')\n",
    "    else:\n",
    "        checkpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    # checkpoint['args']['device'] saves the device used as train time\n",
    "    # if at test time, we are using a CPU, we must override device to None\n",
    "    if not use_gpu:\n",
    "        checkpoint['args'].device = None\n",
    "    net = getattr(models,checkpoint['args'].model)(checkpoint['args'])\n",
    "    net.load_state_dict(checkpoint['model'])\n",
    "    if use_gpu:\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    doc_num = len(test_dataset)\n",
    "    time_cost = 0\n",
    "    file_id = 1\n",
    "    for batch in tqdm(test_iter):\n",
    "        features,_,summaries,doc_lens = vocab.make_features(batch)\n",
    "        t1 = time()\n",
    "        if use_gpu:\n",
    "            probs = net(Variable(features).cuda(), doc_lens)\n",
    "        else:\n",
    "            probs = net(Variable(features), doc_lens)\n",
    "        t2 = time()\n",
    "        time_cost += t2 - t1\n",
    "        start = 0\n",
    "        for doc_id,doc_len in enumerate(doc_lens):\n",
    "            stop = start + doc_len\n",
    "            prob = probs[start:stop]\n",
    "            topk = min(args.topk,doc_len)\n",
    "            topk_indices = prob.topk(topk)[1].cpu().data.numpy()\n",
    "            topk_indices.sort()\n",
    "            doc = batch['doc'][doc_id].split('\\n')[:doc_len]\n",
    "            hyp = [doc[index] for index in topk_indices]\n",
    "            ref = summaries[doc_id]\n",
    "            with open(os.path.join(args.ref,str(file_id)+'.txt'), 'w',encoding=\"utf8\") as f:\n",
    "                f.write(ref)\n",
    "            with open(os.path.join(args.hyp,str(file_id)+'.txt'), 'w',encoding=\"utf8\") as f:\n",
    "                f.write('\\n'.join(hyp))\n",
    "            start = stop\n",
    "            file_id = file_id + 1\n",
    "    print('Speed: %.2f docs / s' % (doc_num / time_cost))\n",
    "    print(\"test ended\")\n",
    "\n",
    "\n",
    "def predict(examples):\n",
    "    embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
    "    with open(args.word2id,encoding=\"utf8\") as f:\n",
    "        word2id = json.load(f)\n",
    "    vocab = Vocab(embed, word2id)\n",
    "    pred_dataset = Dataset(examples)\n",
    "\n",
    "    pred_iter = DataLoader(dataset=pred_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False)\n",
    "    if use_gpu:\n",
    "        checkpoint = torch.load(args.load_dir)\n",
    "    else:\n",
    "        checkpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    # checkpoint['args']['device'] saves the device used as train time\n",
    "    # if at test time, we are using a CPU, we must override device to None\n",
    "    if not use_gpu:\n",
    "        checkpoint['args'].device = None\n",
    "    net = getattr(RNN_RNN,checkpoint['args'].model)(checkpoint['args'])\n",
    "    net.load_state_dict(checkpoint['model'])\n",
    "    if use_gpu:\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    doc_num = len(pred_dataset)\n",
    "    time_cost = 0\n",
    "    file_id = 1\n",
    "    for batch in tqdm(pred_iter):\n",
    "        features, doc_lens = vocab.make_predict_features(batch)\n",
    "        t1 = time()\n",
    "        if use_gpu:\n",
    "            probs = net(Variable(features).cuda(), doc_lens)\n",
    "        else:\n",
    "            probs = net(Variable(features), doc_lens)\n",
    "        t2 = time()\n",
    "        time_cost += t2 - t1\n",
    "        start = 0\n",
    "        for doc_id,doc_len in enumerate(doc_lens):\n",
    "            stop = start + doc_len\n",
    "            prob = probs[start:stop]\n",
    "            topk = min(args.topk,doc_len)\n",
    "            topk_indices = prob.topk(topk)[1].cpu().data.numpy()\n",
    "            topk_indices.sort()\n",
    "            doc = batch[doc_id].split('. ')[:doc_len]\n",
    "            hyp = [doc[index] for index in topk_indices]\n",
    "            with open(os.path.join(args.hyp,str(file_id)+'.txt'), 'w') as f:\n",
    "                f.write('. '.join(hyp))\n",
    "            start = stop\n",
    "            file_id = file_id + 1\n",
    "    print('Speed: %.2f docs / s' % (doc_num / time_cost))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \"\"\" if args.test:\n",
    "        test()\n",
    "    #elif args.predict:\n",
    "     #   with open(args.filename ,encoding=\"utf8\") as file:\n",
    "      #      bod = [file.read()]\n",
    "       # predict(bod)\n",
    "    else:\n",
    "        train()\"\"\"\n",
    "    train()\n",
    "    test()\n",
    "    print(\"everything done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sa\")\n",
    "print(\"args.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-quebec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyrouge import Rouge155\n",
    "def remove_broken_files():\n",
    "    error_id = []\n",
    "    for f in os.listdir('C:/Users/user/Desktop/sondönem/bitirme/outputs/ref'):\n",
    "        try:\n",
    "            open('ref/' + f).read()\n",
    "        except:\n",
    "            error_id.append(f)\n",
    "    for f in os.listdir('C:/Users/user/Desktop/sondönem/bitirme/outputs/hyp'):\n",
    "        try:\n",
    "            open('hyp/' + f).read()\n",
    "        except:\n",
    "            error_id.append(f)\n",
    "    error_set = set(error_id)\n",
    "    for f in error_set:\n",
    "        os.remove('ref/' + f)\n",
    "        os.remove('hyp/' + f)\n",
    "\n",
    "def rouge():\n",
    "    r = Rouge155()\n",
    "    r.home_dir = '.'\n",
    "    r.system_dir = 'C:/Users/user/Desktop/sondönem/bitirme/outputs/hyp'\n",
    "    r.model_dir =  'C:/Users/user/Desktop/sondönem/bitirme/outputs/ref'\n",
    "    \n",
    "    r.system_filename_pattern = '(\\d+).txt'\n",
    "    r.model_filename_pattern = '#ID#.txt'\n",
    "\n",
    "    command = '-e /C:/Users/user/pyrouge/tools/ROUGE-1.5.5/data -a -c 95 -m -n 2 -b 75'\n",
    "    output = r.convert_and_evaluate(rouge_args=command)\n",
    "    print(output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    remove_broken_files()\n",
    "    rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-phase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-military",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION', )\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-friendly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
