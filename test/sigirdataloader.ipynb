{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mobile-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:\\Users\\user\\Desktop\\sondönem\\bitirme\\sigirtestdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "molecular-trace",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-2-4553d4644494>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-4553d4644494>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    with open(args.word2id,encoding=\"utf8\") as f:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "####predict\n",
    "embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
    "    with open(args.word2id,encoding=\"utf8\") as f:\n",
    "        word2id = json.load(f)\n",
    "    vocab = Vocab(embed, word2id)\n",
    "    pred_dataset = Dataset(examples)\n",
    "\n",
    "    pred_iter = DataLoader(dataset=pred_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False)\n",
    "    if use_gpu:\n",
    "        checkpoint = torch.load(args.load_dir)\n",
    "    else:\n",
    "        checkpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    # checkpoint['args']['device'] saves the device used as train time\n",
    "    # if at test time, we are using a CPU, we must override device to None\n",
    "    if not use_gpu:\n",
    "        checkpoint['args'].device = None\n",
    "    net = getattr(RNN_RNN,checkpoint['args'].model)(checkpoint['args'])\n",
    "    net.load_state_dict(checkpoint['model'])\n",
    "    if use_gpu:\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    doc_num = len(pred_dataset)\n",
    "    time_cost = 0\n",
    "    file_id = 1\n",
    "    for batch in tqdm(pred_iter):\n",
    "        features, doc_lens = vocab.make_predict_features(batch)\n",
    "        t1 = time()\n",
    "        if use_gpu:\n",
    "            probs = net(Variable(features).cuda(), doc_lens)\n",
    "        else:\n",
    "            probs = net(Variable(features), doc_lens)\n",
    "        t2 = time()\n",
    "        time_cost += t2 - t1\n",
    "        start = 0\n",
    "        for doc_id,doc_len in enumerate(doc_lens):\n",
    "            stop = start + doc_len\n",
    "            prob = probs[start:stop]\n",
    "            topk = min(args.topk,doc_len)\n",
    "            topk_indices = prob.topk(topk)[1].cpu().data.numpy()\n",
    "            topk_indices.sort()\n",
    "            doc = batch[doc_id].split('. ')[:doc_len]\n",
    "            hyp = [doc[index] for index in topk_indices]\n",
    "            with open(os.path.join(args.hyp,str(file_id)+'.txt'), 'w') as f:\n",
    "                f.write('. '.join(hyp))\n",
    "            start = stop\n",
    "            file_id = file_id + 1\n",
    "    print('Speed: %.2f docs / s' % (doc_num / time_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broke-webster",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-da7ef4ffdecd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-da7ef4ffdecd>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    embed = torch.Tensor(np.load(args.embedding)['embedding'])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "print(\"test started\")\n",
    "    embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
    "    with open(args.word2id,encoding=\"utf8\") as f:\n",
    "        word2id = json.load(f)\n",
    "    vocab = Vocab(embed, word2id)\n",
    "\n",
    "    with open(args.test_dir,encoding=\"utf8\") as f:\n",
    "        examples = [json.loads(line) for line in f]\n",
    "    test_dataset = Dataset(examples)\n",
    "\n",
    "    test_iter = DataLoader(dataset=test_dataset,\n",
    "                            batch_size=args.batch_size,\n",
    "                            shuffle=False)\n",
    "    \n",
    "    if use_gpu:\n",
    "        checkpoint = torch.load(args.load_dir)#-load_dir',type=str,default='C:/Users/user/metin özütleme/hphaos summarunner/checkpoint/RNN_RNN_seed_1.pt')\n",
    "    else:\n",
    "        checkpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    # checkpoint['args']['device'] saves the device used as train time\n",
    "    # if at test time, we are using a CPU, we must override device to None\n",
    "    if not use_gpu:\n",
    "        checkpoint['args'].device = None\n",
    "    net = getattr(RNN_RNN,checkpoint['args'].model)(checkpoint['args'])\n",
    "    net.load_state_dict(checkpoint['model'])\n",
    "    if use_gpu:\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    doc_num = len(test_dataset)\n",
    "    time_cost = 0\n",
    "    file_id = 1\n",
    "    for batch in tqdm(test_iter):\n",
    "        features,_,summaries,doc_lens = vocab.make_features(batch)\n",
    "        t1 = time()\n",
    "        if use_gpu:\n",
    "            probs = net(Variable(features).cuda(), doc_lens)\n",
    "        else:\n",
    "            probs = net(Variable(features), doc_lens)\n",
    "        t2 = time()\n",
    "        time_cost += t2 - t1\n",
    "        start = 0\n",
    "        for doc_id,doc_len in enumerate(doc_lens):\n",
    "            stop = start + doc_len\n",
    "            prob = probs[start:stop]\n",
    "            topk = min(args.topk,doc_len)\n",
    "            topk_indices = prob.topk(topk)[1].cpu().data.numpy()\n",
    "            topk_indices.sort()\n",
    "            doc = batch['doc'][doc_id].split('\\n')[:doc_len]\n",
    "            hyp = [doc[index] for index in topk_indices]\n",
    "            ref = summaries[doc_id]\n",
    "            with open(os.path.join(args.ref,str(file_id)+'.txt'), 'w',encoding=\"utf8\") as f:\n",
    "                f.write(ref)\n",
    "            with open(os.path.join(args.hyp,str(file_id)+'.txt'), 'w',encoding=\"utf8\") as f:\n",
    "                f.write('\\n'.join(hyp))\n",
    "            start = stop\n",
    "            file_id = file_id + 1\n",
    "    print('Speed: %.2f docs / s' % (doc_num / time_cost))\n",
    "    print(\"test ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blond-object",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-b456cf3c302f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-b456cf3c302f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    '1\\n0\\n1\\n1\\n0\\n1\\n0\\n0\\n1\\n1\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0', 'summaries':\u001b[0m\n\u001b[1;37m                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'1\\n0\\n1\\n1\\n0\\n1\\n0\\n0\\n1\\n1\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0', 'summaries':\n",
    "'1\\n0\\n1\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n1', 'summaries':\n",
    "'1\\n0\\n1\\n1\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\n0\\n1', 'summaries':\n",
    "'1\\n1\\n1\\n0\\n1\\n0\\n1\\n0\\n0\\n1\\n1\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\n0\\n0\\n1\\n1\\n0\\n0\\n0', 'summaries':\n",
    "    {'doc': 'with the trademark curly hair and giant personality , it is difficult for jones to blend into the background\\nthe uninformed supporter still stops the welsh prop in the street to commiserate with him on his country â\\x80\\x99s latest defeat , \n",
    "     unaware that he is no longer in the squad\\njones has been a household feature in wales teams over the last decade and is one of the most recognisable and popular figures to wear the dragon red jersey\\nthe 33 - year - \n",
    "     old has experienced some tough autumn evenings at the millennium stadium , but none quite as difficult as this november , having been left out of the squad for the first time in his career\\njonathan davies ( left ) , jones ( centre )\n",
    "     and ian evans sing the welsh national anthem wales coach warren gatland has opted for young prop samson lee over veteran tighhead jones jones ( right ) moved to the cardiff blues from the ospreys during the summer the frontrower admits\n",
    "     it has been â\\x80\\x98 tough â\\x80\\x99 and â\\x80\\x98 odd â\\x80\\x99 as an outsider looking in , but has still not given up hope of making next year â\\x80\\x99s world cup squad , even if it is just to avoid those awkward moments in the\n",
    "     supermarket\\nâ\\x80\\x98 someone â\\x80\\x99s wife came up to me in tesco and said â\\x80\\x9c unlucky at the weekend , you almost beat â\\x80\\x98 em \" , \\' said jones\\nâ\\x80\\x98 then the bloke nudged her and said â\\x80\\x9c he was nâ\\x80\\x99t \n",
    "     playing , he was nâ\\x80\\x99t picked ! â\\x80\\x9d it â\\x80\\x99s happened a couple of times ; people assume i was there because i â\\x80\\x99ve been involved for such a long time\\ni guess i â\\x80\\x99m quite recognisable with the hair\n",
    "     and that\\nthat â\\x80\\x99s been the hardest bit\\ni always had a good rapport but i have nâ\\x80\\x99t given up on the dream quite yet\\nâ\\x80\\x99 a summer move from the ospreys to cardiff blues has given the forward renewed hope\\njones \n",
    "     was caught in the crossfire of the funding row between the wru and the regions , which has now been resolved , and found himself unemployed and without a club when he returned from the summer tour to south africa\\njones ( left )\n",
    "     and wales captain sam warburton catch a breather against ireland in cardiff in february 2013 he turned to his first club neath , who he joined in 2000 as a part - time labourer making patio slabs\\nthey invited the welshman to join \n",
    "     their pre-season training and , after coming close to hanging up his boots , jones was offered an alluring opportunity with the cardiff blues\\nâ\\x80\\x98 i â\\x80\\x99d be lying if i said i did nâ\\x80\\x99t fancy knocking it on the head\n",
    "     and saying , â\\x80\\x9c f * * * it , i â\\x80\\x99ll just go to university or something â\\x80\\x9d , â\\x80\\x99 said jones\\nâ\\x80\\x98 i missed the day - to - day camaraderie of being in a team ; all the chopping and the p * * * taking\\nyou \n",
    "     become pretty used to something when you â\\x80\\x99ve been doing it for 14 or so years\\nâ\\x80\\x98 not having an income was a bit of a ball ache too , but i â\\x80\\x99d been pretty thrifty so i always had a bit saved up\\nit dragged on for \n",
    "     months but i was always thought in the back of my head that i still had something to offer\\nthen cardiff came in on the sunday and it was all done by tuesday\\nthe whole thing made me realise how important rugby was to me\\ni â\\x80\\x99d \n",
    "     have been pretty dumb to pack it all in\\nâ\\x80\\x99 jones and fellow front row veteran gethin jenkins ( left ) celebrate with the 2013 six nations title a lack of fitness was warren gatland â\\x80\\x99s reason for substituting jones 32 minutes\n",
    "     into his milestone 100th test against south africa at kings park in june\\njones was left out of the squad for the second test altogether and he has not played for his country since\\nit harked back to 2003 , when jones became known as the\n",
    "     â\\x80\\x99 30 - minute man â\\x80\\x99 after he was hauled off by steve hansen early in the world cup quarter - final in brisbane against england , but the latest episode was more painful\\nfor a player who was being courted for interviews all \n",
    "     week ahead of the test in durban , it was a huge crash down to earth\\nâ\\x80\\x98 it was my 100th test match so to go from such a high to getting hauled off was nâ\\x80\\x99t nice , â\\x80\\x99 said jones\\nâ\\x80\\x98 i â\\x80\\x99m not going to lie ,\n",
    "     the last week out there was hard work\\ni â\\x80\\x99m not sure how i would have coped without ian evans [ the veteran second row ]\\ni â\\x80\\x99m probably still bitter about it now but it â\\x80\\x99s happened\\njones , speaking to the media during \n",
    "     the 2013 lions tour of australia , has always been a popular figure â\\x80\\x98 it was harder this time than in 2003 , because i â\\x80\\x99m so much further down the line\\ni â\\x80\\x99ve got to a certain standing and achieved things \n",
    "     , so it hurt more\\nwhen i was younger it happened and i just had to suck it and see\\nbut i understand that gats and these guys get paid to make these big decisions and they have to do what works for them\\nâ\\x80\\x99 warren gatland turned to\n",
    "     21 year - old samson lee , who is regarded as jones â\\x80\\x99 long - term successor\\nthe scarlets prop has started every test since jones was ousted and has the seal of approval from the man himself\\nâ\\x80\\x98 samson lee is excellent , \n",
    "     â\\x80\\x99 said jones\\nâ\\x80\\x98 he â\\x80\\x99s been phenomenal for his club and i think we â\\x80\\x99ve got a little gem there\\nguys like him and nicky smith will be around for the next 10 years now and i think samson lee will be a shoo \n",
    "     in for the lions\\nhe â\\x80\\x99s a tough little f * * * * * and does nâ\\x80\\x99t give a s * * * about reputations\\nhe â\\x80\\x99s someone we can build our team around over the next 10 years\\nâ\\x80\\x99 samson lee may be the future , but\n",
    "     jones is not ready to consign himself to the past', \n",
    "     'labels': '1\\n0\\n1\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n1', \n",
    "     'summaries': 'jones won his 100th cap for wales during the summer\\nthe 33 - year - old tighthead has played no part in autumn series\\nwales coach warren gatland has \n",
    "     preferred samson lee to jones\\njones moved from the ospreys to cardiff blues this season'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter last updated at 11:49 am on 5th october 2011 documents obtained under a federal freedom of information act lawsuit filed by judicial watch detail costs incurred during the first lady 's trip to africa and botswana in june - with the cost of firing up ' air force 2 ' alone amounting to $ 424,142\\nthe white house earlier professed the purpose of the trip was to help ' youth leadership , education , health and wellness ' in africa\\n' air force 2 ' : obama waves as she boards her private plane after a week - long trip to africa in june\\ncosts of the flight are estimated to tally more than $ 424,000 greetings : mrs obama was met by excited children when she arrived to botswana on june 24 warm welcome : mrs obama with daughters sasha , far right , and malia , right , were greeted by traditional dancers as they arrive in gaborone , botswana judicial watch said it based the jet costs on the u.s. department of defense 's published hourly rates for the c-32a aircraft - a specifically configured military version of the boeing 757\\nduring the june 21 - 27 trip , the group accounted for 34.8 flight hours at $ 12,188 per hour\\nthat does not include a tally of local transportation , secret service protection , food for the 21 family and staff members - and the cost of pre-trip preparations contributing to the final amount\\nthose figures have yet to be disclosed\\naccording to the release , the passenger manifests confirm the presence of obama 's daughter 's , malia and sasha on the trip\\nthe two girls are listed as ' senior staff\\n' family safari : mrs obama , joined by her daughters sasha and malia and her mother marian robinson enjoyed a ride through madikwe game reserve during the trip encouraging : mrs obama stands with mamphela ramphele , fifth from right , and high school students after she answered students ' questions at the university of cape town in cape town , africa on june 23 playful : mrs obama ( r ) and daughters sasha ( c ) and malia take turns read to students during a visit to the emthonjeni community center in zandspruit township , johannesburg , africa on june 21 goals : mrs obama said the trip would help ' youth leadership , education , health and wellness ' in southern africa , according to the white house the manifests also list mrs obama 's mother , marian robinson , and niece and nephew , leslie and avery robinson , as well mrs. obama 's make - up and hairstylist ( carl ray and johnny wright )\\nthe expense records also show $ 928.44 was spent for ' bulk food ' purchases on flight\\noverall , during the trip , 192 meals were served for the 21 passengers on board\\nthe ' professed purpose ' of the trip ' was to encourage young people living in the two growing democracies to become involved in national affairs ; and during her scheduled stops in pretoria and cape town , africa and in gaborone , the capital of botswana , the first lady used the opportunity to speak on education , health and wellness issues , ' the report states\\nmemorable : mrs obama also took her daughters to visit nelson mandela , a visit which she called ' surreal ' family : from left , mrs obama 's niece leslie robinson , malia , archbishop desmond tutu , mrs obama , sasha obama and nephew avery robinsona at cape town stadium in africa on june 23 business : mrs obama met botswana 's president lt. gen. seretse khama ian khama during her visit mission expense records and passenger manifests from the air force related to the june 21 - 27 , 2011 trip taken by first lady obama , her family and her staff to africa and botswana , according to watchdog group judicial watch include : the malia also enjoyed a meet up with nelson mandela\\nhowever , the trip also included visits to historical landmarks , and ended with a private family safari at a africa game reserve before the group returned to washington on june 27\\njudicial watch , which investigates and fights government corruption , said in a press release issued today it is investigating the purpose and itinerary of the trip\\non june 28 , 2011 , the group filed a freedom of information act request seeking the mission taskings , transportation records , and passenger manifests for obama 's africa trip\\ndocuments were only provided after judicial watch sued to obtain the documents , according to the release\\n' this trip was as much an opportunity for the obama family to go on a safari as it was a trip to conduct government business , ' said judicial watch president tom fitton\\n' this junket wasted tax dollars and the resources of our overextended military\\nno wonder we had to sue to pry loose this information\", \"labels\": \"1\\n0\\n1\\n1\\n0\\n1\\n0\\n0\\n1\\n1\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\", \"summaries\": \"costs of ' air force 2 ' flight amount to over $ 424,000 , air force manifests indicate\\nin - flight meals for 21 passengers cost over $ 900\\nfirst daughters malia , 13 , and sasha obama , 10 , listed as ' senior staff ' in manifests\"}\n",
    "{\"doc\": \"with the trademark curly hair and giant personality , it is difficult for jones to blend into the background\\nthe uninformed supporter still stops the welsh prop in the street to commiserate with him on his country âs latest defeat , unaware that he is no longer in the squad\\njones has been a household feature in wales teams over the last decade and is one of the most recognisable and popular figures to wear the dragon red jersey\\nthe 33 - year - old has experienced some tough autumn evenings at the millennium stadium , but none quite as difficult as this november , having been left out of the squad for the first time in his career\\njonathan davies ( left ) , jones ( centre ) and ian evans sing the welsh national anthem wales coach warren gatland has opted for young prop samson lee over veteran tighhead jones jones ( right ) moved to the cardiff blues from the ospreys during the summer the frontrower admits it has been â tough â and â odd â as an outsider looking in , but has still not given up hope of making next year âs world cup squad , even if it is just to avoid those awkward moments in the supermarket\\nâ someone âs wife came up to me in tesco and said â unlucky at the weekend , you almost beat â em \\\" , ' said jones\\nâ then the bloke nudged her and said â he was nât playing , he was nât picked ! â it âs happened a couple of times ; people assume i was there because i âve been involved for such a long time\\ni guess i âm quite recognisable with the hair and that\\nthat âs been the hardest bit\\ni always had a good rapport but i have nât given up on the dream quite yet\\nâ a summer move from the ospreys to cardiff blues has given the forward renewed hope\\njones was caught in the crossfire of the funding row between the wru and the regions , which has now been resolved , and found himself unemployed and without a club when he returned from the summer tour to south africa\\njones ( left ) and wales captain sam warburton catch a breather against ireland in cardiff in february 2013 he turned to his first club neath , who he joined in 2000 as a part - time labourer making patio slabs\\nthey invited the welshman to join their pre-season training and , after coming close to hanging up his boots , jones was offered an alluring opportunity with the cardiff blues\\nâ i âd be lying if i said i did nât fancy knocking it on the head and saying , â f * * * it , i âll just go to university or something â , â said jones\\nâ i missed the day - to - day camaraderie of being in a team ; all the chopping and the p * * * taking\\nyou become pretty used to something when you âve been doing it for 14 or so years\\nâ not having an income was a bit of a ball ache too , but i âd been pretty thrifty so i always had a bit saved up\\nit dragged on for months but i was always thought in the back of my head that i still had something to offer\\nthen cardiff came in on the sunday and it was all done by tuesday\\nthe whole thing made me realise how important rugby was to me\\ni âd have been pretty dumb to pack it all in\\nâ jones and fellow front row veteran gethin jenkins ( left ) celebrate with the 2013 six nations title a lack of fitness was warren gatland âs reason for substituting jones 32 minutes into his milestone 100th test against south africa at kings park in june\\njones was left out of the squad for the second test altogether and he has not played for his country since\\nit harked back to 2003 , when jones became known as the â 30 - minute man â after he was hauled off by steve hansen early in the world cup quarter - final in brisbane against england , but the latest episode was more painful\\nfor a player who was being courted for interviews all week ahead of the test in durban , it was a huge crash down to earth\\nâ it was my 100th test match so to go from such a high to getting hauled off was nât nice , â said jones\\nâ i âm not going to lie , the last week out there was hard work\\ni âm not sure how i would have coped without ian evans [ the veteran second row ]\\ni âm probably still bitter about it now but it âs happened\\njones , speaking to the media during the 2013 lions tour of australia , has always been a popular figure â it was harder this time than in 2003 , because i âm so much further down the line\\ni âve got to a certain standing and achieved things , so it hurt more\\nwhen i was younger it happened and i just had to suck it and see\\nbut i understand that gats and these guys get paid to make these big decisions and they have to do what works for them\\nâ warren gatland turned to 21 year - old samson lee , who is regarded as jones â long - term successor\\nthe scarlets prop has started every test since jones was ousted and has the seal of approval from the man himself\\nâ samson lee is excellent , â said jones\\nâ he âs been phenomenal for his club and i think we âve got a little gem there\\nguys like him and nicky smith will be around for the next 10 years now and i think samson lee will be a shoo in for the lions\\nhe âs a tough little f * * * * * and does nât give a s * * * about reputations\\nhe âs someone we can build our team around over the next 10 years\\nâ samson lee may be the future , but jones is not ready to consign himself to the past\", \"labels\": \"1\\n0\\n1\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n1\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n1\", \"summaries\": \"jones won his 100th cap for wales during the summer\\nthe 33 - year - old tighthead has played no part in autumn series\\nwales coach warren gatland has preferred samson lee to jones\\njones moved from the ospreys to cardiff blues this season\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "interim-circle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc': '', 'labels': '', 'summaries': ''}\n",
      "\n",
      "reading abstract\n",
      "\n",
      "\n",
      "--------------------------\n",
      "abstrat generated\n",
      "-----ABSTRACT------\n",
      "\n",
      "readin intro\n",
      "\n",
      "--------------------------\n",
      "With huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\n",
      "The end user sees fast queries because the dataset is partitioned across many machines\n",
      "However, resource costs are still present, so any improvement in efficiency will give significant cost savings\n",
      "In this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\n",
      "The details of executing queries in a search system are complex, but the basic idea is simple.\n",
      "At indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\n",
      "Each list is stored in a compressed format and often in document identifier (docid) order\n",
      "Within-document locations are often dropped and only \"docid, frequency\" pairs are stored\n",
      "At query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\n",
      "The standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\n",
      "During list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\n",
      "The exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\n",
      "The exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\n",
      "The WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\n",
      "The details of this transition produce both fast query execution and rank-safe results\n",
      "The WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\n",
      "This is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\n",
      " The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\n",
      "Thus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\n",
      "The required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\n",
      "We start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\n",
      "We then improve upon this original code in three ways:\n",
      "First, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements. ', \n",
      "Second, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\n",
      "Third, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\n",
      "While the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined\n",
      "doc generated\n",
      "-----DOC------\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n",
      "reading abstract\n",
      "\n",
      "\n",
      "--------------------------\n",
      "abstrat generated\n",
      "-----ABSTRACT------\n",
      "\n",
      "readin intro\n",
      "\n",
      "--------------------------\n",
      "With huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\n",
      "The end user sees fast queries because the dataset is partitioned across many machines\n",
      "However, resource costs are still present, so any improvement in efficiency will give significant cost savings\n",
      "In this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\n",
      "The details of executing queries in a search system are complex, but the basic idea is simple.\n",
      "At indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\n",
      "Each list is stored in a compressed format and often in document identifier (docid) order\n",
      "Within-document locations are often dropped and only \"docid, frequency\" pairs are stored\n",
      "At query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\n",
      "The standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\n",
      "During list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\n",
      "The exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\n",
      "The exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\n",
      "The WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\n",
      "The details of this transition produce both fast query execution and rank-safe results\n",
      "The WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\n",
      "This is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\n",
      " The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\n",
      "Thus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\n",
      "The required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\n",
      "We start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\n",
      "We then improve upon this original code in three ways:\n",
      "First, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements. ', \n",
      "Second, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\n",
      "Third, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\n",
      "While the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined\n",
      "doc generated\n",
      "-----DOC------\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n",
      "reading abstract\n",
      "\n",
      "\n",
      "--------------------------\n",
      "abstrat generated\n",
      "-----ABSTRACT------\n",
      "\n",
      "readin intro\n",
      "\n",
      "--------------------------\n",
      "With huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\n",
      "The end user sees fast queries because the dataset is partitioned across many machines\n",
      "However, resource costs are still present, so any improvement in efficiency will give significant cost savings\n",
      "In this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\n",
      "The details of executing queries in a search system are complex, but the basic idea is simple.\n",
      "At indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\n",
      "Each list is stored in a compressed format and often in document identifier (docid) order\n",
      "Within-document locations are often dropped and only \"docid, frequency\" pairs are stored\n",
      "At query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\n",
      "The standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\n",
      "During list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\n",
      "The exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\n",
      "The exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\n",
      "The WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\n",
      "The details of this transition produce both fast query execution and rank-safe results\n",
      "The WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\n",
      "This is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\n",
      " The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\n",
      "Thus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\n",
      "The required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\n",
      "We start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\n",
      "We then improve upon this original code in three ways:\n",
      "First, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements. ', \n",
      "Second, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\n",
      "Third, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\n",
      "While the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined\n",
      "doc generated\n",
      "-----DOC------\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n",
      "reading abstract\n",
      "\n",
      "\n",
      "--------------------------\n",
      "abstrat generated\n",
      "-----ABSTRACT------\n",
      "\n",
      "readin intro\n",
      "\n",
      "--------------------------\n",
      "With huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\n",
      "The end user sees fast queries because the dataset is partitioned across many machines\n",
      "However, resource costs are still present, so any improvement in efficiency will give significant cost savings\n",
      "In this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\n",
      "The details of executing queries in a search system are complex, but the basic idea is simple.\n",
      "At indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\n",
      "Each list is stored in a compressed format and often in document identifier (docid) order\n",
      "Within-document locations are often dropped and only \"docid, frequency\" pairs are stored\n",
      "At query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\n",
      "The standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\n",
      "During list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\n",
      "The exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\n",
      "The exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\n",
      "The WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\n",
      "The details of this transition produce both fast query execution and rank-safe results\n",
      "The WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\n",
      "This is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\n",
      " The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\n",
      "Thus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\n",
      "The required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\n",
      "We start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\n",
      "We then improve upon this original code in three ways:\n",
      "First, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements. ', \n",
      "Second, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\n",
      "Third, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\n",
      "While the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined\n",
      "doc generated\n",
      "-----DOC------\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n",
      "reading abstract\n",
      "\n",
      "\n",
      "--------------------------\n",
      "abstrat generated\n",
      "-----ABSTRACT------\n",
      "\n",
      "readin intro\n",
      "\n",
      "--------------------------\n",
      "With huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\n",
      "The end user sees fast queries because the dataset is partitioned across many machines\n",
      "However, resource costs are still present, so any improvement in efficiency will give significant cost savings\n",
      "In this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\n",
      "The details of executing queries in a search system are complex, but the basic idea is simple.\n",
      "At indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\n",
      "Each list is stored in a compressed format and often in document identifier (docid) order\n",
      "Within-document locations are often dropped and only \"docid, frequency\" pairs are stored\n",
      "At query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\n",
      "The standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\n",
      "During list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\n",
      "The exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\n",
      "The exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\n",
      "The WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\n",
      "The details of this transition produce both fast query execution and rank-safe results\n",
      "The WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\n",
      "This is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\n",
      " The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\n",
      "Thus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\n",
      "The required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\n",
      "We start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\n",
      "We then improve upon this original code in three ways:\n",
      "First, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements. ', \n",
      "Second, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\n",
      "Third, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\n",
      "While the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined\n",
      "doc generated\n",
      "-----DOC------\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n",
      "reading abstract\n",
      "\n",
      "\n",
      "--------------------------\n",
      "abstrat generated\n",
      "-----ABSTRACT------\n",
      "\n",
      "readin intro\n",
      "\n",
      "--------------------------\n",
      "With huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\n",
      "The end user sees fast queries because the dataset is partitioned across many machines\n",
      "However, resource costs are still present, so any improvement in efficiency will give significant cost savings\n",
      "In this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\n",
      "The details of executing queries in a search system are complex, but the basic idea is simple.\n",
      "At indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\n",
      "Each list is stored in a compressed format and often in document identifier (docid) order\n",
      "Within-document locations are often dropped and only \"docid, frequency\" pairs are stored\n",
      "At query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\n",
      "The standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\n",
      "During list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\n",
      "The exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\n",
      "The exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\n",
      "The WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\n",
      "The details of this transition produce both fast query execution and rank-safe results\n",
      "The WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\n",
      "This is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\n",
      " The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\n",
      "Thus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\n",
      "The required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\n",
      "We start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\n",
      "We then improve upon this original code in three ways:\n",
      "First, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements. ', \n",
      "Second, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\n",
      "Third, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\n",
      "While the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined\n",
      "doc generated\n",
      "-----DOC------\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n",
      "{'doc': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe end user sees fast queries because the dataset is partitioned across many machines\\nHowever, resource costs are still present, so any improvement in efficiency will give significant cost savings\\nIn this paper, we present various optimization techniques for search execution that maintain the ranking effectiveness of the system, so called rank-safe execution.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nAt indexing time, the data is inverted to form a postings list for each token containing the locations of that token in the dataset\\nEach list is stored in a compressed format and often in document identifier (docid) order\\nWithin-document locations are often dropped and only \"docid, frequency\" pairs are stored\\nAt query time, the system finds the lists for the query terms and combines them to give the top-k best documents according to a specified ranking algorithm\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-OR method considers all documents in all the query lists (disjunctive merging), resulting in slow queries, but rank-safe results since every candidate is scored\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThe WAND (Weak-AND) [4] and state-of-the-art BMW (Block- Max WAND) [10] approaches start executing as an OR query and transition towards an AND as intermediate results improve\\nThe details of this transition produce both fast query execution and rank-safe results\\nThe WAND approach uses the current top-k results stored in the heap to give a threshold allowing more efficient skipping of potential candidates during SELECT processing\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\n The BMW approach adds maximum scores for each encoded list block in the index, and uses them to prune candidates on each pivot calculation\\nThus, both approaches change SELECT processing to reduce candidates sent to the SCORE stage.\\nThe required additions to the basic search execution loop are marked in Figure 1 (green italic writing).\\nWe start with a recent WAND and BMW implementation using quantized scores and incremental scoring for fast execution [6]\\nWe then improve upon this original code in three ways:\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations\\nWhile the 2-layer approach has been used with BMW [9, 10], the 2-layer split-list WAND approach has not been previously examined', 'labels': '1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n1\\\\n', 'summaries': '\\nWith huge amounts of data and large query volumes, search engines consume significant resources, both in terms of computer hardware and energy usage.\\nThe details of executing queries in a search system are complex, but the basic idea is simple.\\nThe standard approach merges lists ordered by docid, resulting in document-at-a-time execution that is fast and requires little temporary memory [5]\\nDuring list merging, each iteration of the search execution loop will SELECT the next candidate document, SCORE the candidate, and possibly SAVE it in a top-k heap, as depicted in Figure 1 (ignoring the green italic writing for now)\\nThe exhaustive-AND method considers only documents contained in all the query lists (conjunctive merging), resulting in fast queries, but non-rank-safe results since high-scoring documents missing one or more terms are not found\\nThis is done by ordering the query lists by their current docid and summing up their maximum list scores —in order— until it exceeds the threshold at the pivot docid; then the smallest list before the pivot is advanced, and a new pivot is calculated, repeating until enough lists are on the same pivot docid to score the candidate\\nFirst, we apply small code optimizations to both the WAND and BMW implementations that give significant runtime improvements.  \\nSecond, we improve the query runtime of the WAND and BMW algorithms for large k values by starting at an initial threshold generated from indexing time analysis of the query lists.\\nThird, we show that split-lists (i.e., 2-layer lists split by score) can significantly improve WAND performance, making it faster than the state-of-the-art BMW approach for many configurations'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Module\n",
    "import os\n",
    "import re\n",
    "dir = \"C:/Users/user/Desktop/sondönem/bitirme/sigirtestdata\" \n",
    "finaldoc=[]\n",
    "mydict={}\n",
    "finalstr=\"\"\n",
    "newlinecount=0\n",
    "labels=\"\"\n",
    "keys=['doc', 'labels','summaries']\n",
    "for i in keys:\n",
    "    mydict[i] = \"\"\n",
    "for dirPath, foldersInDir,fileName in os.walk(dir):\n",
    "    if fileName is not []:\n",
    "        for file in fileName:\n",
    "            if file.endswith('t.txt'):\n",
    "                print(\"reading abstract\")\n",
    "                print()\n",
    "                loc = os.sep.join([dirPath,file])\n",
    "                abstract=open(loc)\n",
    "                abst=abstract.read()\n",
    "                #print(abst)\n",
    "                print()\n",
    "                #lines = abst.split(\"\\n\")\n",
    "                #print(lines)\n",
    "                print(\"--------------------------\")\n",
    "                m = re.findall('1\">(.+?).</', str(lines))\n",
    "                if m:\n",
    "                    for t in m:\n",
    "                        t = t.replace(\"',\", \"\")\n",
    "                        t = t.replace(\"'\", \"\")\n",
    "                        finalstr=finalstr+\"\\n\"+t\n",
    "                        mydict['summaries']=finalstr\n",
    "                #doc format: {'doc': \"text seperated with \\n , 'labels':1\\n...\\n1, 'summaries': 'summary seperated by \\n' \"\n",
    "                \n",
    "                \"\"\"Counter=0\n",
    "                for i in lines:\n",
    "                    if i:\n",
    "                        Counter += 1\n",
    "                print(Counter)\n",
    "                abstract.close()\n",
    "                abstract=open(loc)\n",
    "                lines=abstract.readlines()\n",
    "                #print(lines)\n",
    "                for i in range(0,Counter):\n",
    "                    if \"ABSTRACT\" not in lines[i]:\n",
    "                        print(lines[i])\n",
    "                #print(abst)\"\"\"\n",
    "                #print(mydict)\n",
    "                print(\"abstrat generated\")\n",
    "                print(\"-----ABSTRACT------\")\n",
    "                print()\n",
    "                finalstr=\"\"\n",
    "                \n",
    "            if file.endswith('o.txt'):\n",
    "                \n",
    "                print(\"readin intro\")\n",
    "                loc = os.sep.join([dirPath,file])\n",
    "                doc=open(loc,encoding=\"utf8\")\n",
    "                doc=doc.read()\n",
    "                #print(doc)\n",
    "                print()\n",
    "                #lines = doc.split(\"\\n\")\n",
    "                #print(lines)\n",
    "                print(\"--------------------------\")\n",
    "                #text = 'gfgfdAAA1234ZZZuijjk'\n",
    "                #while m!=[]:\n",
    "                m = re.findall('\"[0-9]\">(.+?).</', str(lines))\n",
    "                if m:\n",
    "                    for t in m:\n",
    "                        print(t)\n",
    "                        labels=labels+\"1\\ n\"\n",
    "                        labels=labels.replace(\" \",\"\")\n",
    "                        newlinecount=newlinecount+1\n",
    "                        t = t.replace(\"',\", \"\")\n",
    "                        t = t.replace(\"'\", \"\")\n",
    "                        finalstr=finalstr+\"\\n\"+t\n",
    "                        mydict['doc']=finalstr\n",
    "                        mydict['labels']=labels\n",
    "                #doc format: {'doc': \"text seperated with \\n , 'labels':1\\n...\\n1, 'summaries': 'summary seperated by \\n' \"\n",
    "                \n",
    "                \"\"\"Counter=0\n",
    "                for i in lines:\n",
    "                    if i:\n",
    "                        Counter += 1\n",
    "                print(Counter)\n",
    "                abstract.close()\n",
    "                abstract=open(loc)\n",
    "                lines=abstract.readlines()\n",
    "                #print(lines)\n",
    "                for i in range(0,Counter):\n",
    "                    if \"ABSTRACT\" not in lines[i]:\n",
    "                        print(lines[i])\n",
    "                #print(abst)\"\"\"\n",
    "                print(\"doc generated\")\n",
    "                print(\"-----DOC------\")\n",
    "                print()\n",
    "                #print(\"00000000000000000\",labels)\n",
    "                \n",
    "        #print(newlinecount)     \n",
    "        print(mydict)\n",
    "        finalstr=\"\"\n",
    "        newlinecount=0\n",
    "        print()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'doc': 'johnathan isaby , chief executive of the tax payers â\\x80\\x99 alliance , called the number of communications staff â\\x80\\x98 blatant hypocrisy â\\x80\\x99 taxpayer money is being used to fund an â\\x80\\x98 army â\\x80\\x99 of spin doctors with more than 3,400 press officers employed by local councils across the uk\\nthe number of communications employees working for local government is more than two times that working across 20 central government departments\\nlondon has at least 425 marketing staff and press officers working across its local authorities , four times more than the entire editorial staff at the evening standard , the times reported\\nnearly 45 councils employ 20 or more communications staff each , with manchester city council the worst offender for its size\\nit has 77 individuals working for it in pr and similar areas\\nleeds city council comes second with 47 staff and bristol and sheffield city come joint third\\nglasgow city council and the kirklees metropolitan borough council in yorkshire each employed 40 pr officers and individuals in similar fields\\nthe figures were unveiled in a freedom of information act request by press gazette to 435 city , district and borough councils to which 405 replied with information about their communications staff\\nthe figures were unveiled in a freedom of information act request by\n",
    " press gazette to 435 city , district and borough councils to which 405 replied with information about their communications staff\\npress gazette made a similar request to central government over\n",
    " its pr staff during another investigation last year\\nfigures revealed that the home office had 275 full - time positions in marketing , press relations and similar areas\\nmanchester city council\n",
    " ( pictured ) was the worst offender for its size\\nit had 77 individuals working for it in pr and similar areas the cabinet office had 205 pr staff and the department for work and pensions had 184\\n\n",
    " johnathan isaby , the chief executive of the tax payers â\\x80\\x99 alliance was quoted as saying it was â\\x80\\x98 blatant hypocrisy â\\x80\\x99 for councils to comment so often on the need for necessary s\n",
    " aving while keeping on so many staff for communications\\nhe added that the next central government needed to crack down on the â\\x80\\x98 army of propagandists â\\x80\\x99 funded by the taxpayer\\nhe sai\n",
    " d those footing the bill expected their money to go to front line services not spin doctors .', \n",
    " 'labels': '1\\n1\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\n0\\n0\\n1\\n1',\n",
    " 'summaries': \"taxpayer money used to pay for an ' army ' of spin doctors in local areas\\nthe number of communications staff in local government more than 3,400\\ntotal is more than double the number working across central government\\nlondon has 425 members of pr staff working across its local authorities\"} dsa\n",
    " {'doc': \"a woman was killed instantly on wednesday after she drove her suv around an active crossing gate and collided with an amtrak train in mississippi\\nthe collision happened about 3pm on norfolk southern railway tracks near downtown meridian , according to lauderdale county coroner cobler\\ncobler said he was withholding the 57 - year - old woman 's name until all family members had been notified\\na woman died instantly on wednesday after she drove her suv around an active crossing gate and collided with an amtrak crescent train in meridian , mississippi ( stock image ) the coroner said the woman drove around functioning gates and flashers and collided with the southbound amtrak crescent\\nhe said her suv was pushed nearly a quarter - mile\\nno one else was in the vehicle\\namtrak spokeswoman vernae graham said there were no injuries among the 51 passengers and crew\\nshe said the train continued its trip from new york toward new orleans after an hour 's delay\\nlocal authorities will conduct an investigation that amtrak will review\\nthe last amtrak fatality in mississippi before wednesday was at a copiah county crossing in january 2013\\nthe coroner said the woman drove around functioning gates and flashers at the gate near downtown meridian in mississippi\", 'labels': '1\\n0\\n1\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n1', 'summaries': 'the 57 - year - old woman was killed when her suv was hit by a train in meridian , mississippi\\nthe coroner said the woman drove around functioning gates and flashers and collided with the southbound amtrak crescent'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(args.train_dir,encoding=\"utf8\") as f:\n",
    "        #examples = [json.loads(line) for line in f]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
